{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python38264bitthrowcondac6bd6c5b69534af0ae472775a9c93db0",
      "display_name": "Python 3.8.2 64-bit ('throw': conda)"
    },
    "colab": {
      "name": "KNN.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5QZBmy9pOzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "import dotenv\n",
        "from os import getenv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from json import loads\n",
        "from pandas.io.json import json_normalize\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsTransformer\n",
        "\n",
        "import pickle\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va8xvKZHpOzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer():\n",
        "    def __init__(self):\n",
        "        # try to load data from .env\n",
        "\n",
        "        self.load_data()\n",
        "\n",
        "        self.tokenizer = Tokenizer(num_words=1000, lower=True)\n",
        "        return\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"A function that takes the DATABASE_URL and fetches the contents of the\n",
        "        strain_info table then saves it to a df\n",
        "        \"\"\"\n",
        "        dotenv.load_dotenv()\n",
        "        alt = 'DATABASE_URL'\n",
        "        db_url = getenv(\"DATASOURCE\", default=alt)\n",
        "        \n",
        "        engine = create_engine(db_url)\n",
        "        df = pd.read_sql(\"SELECT * FROM strain_info\", engine)\n",
        "        self.df = df\n",
        "        return df\n",
        "\n",
        "    def transform(self, document: pd.DataFrame, negative: list, ignore: list) -> pd.DataFrame:\n",
        "        \"\"\"A function that takes the document input and transforms it into a MinMax\n",
        "        scaled DataFrame that represents the term frequency matrix.\n",
        "        this method adds the dtm's for each feature then subtracts the neg feature's dtm\n",
        "        then scales the data with a MinMaxScalar from sklearn.preprocessing\n",
        "        Arguments:\n",
        "        -------------\n",
        "        document {list} : An array like list of strings representing a document to be transformed\n",
        "        negitive {list} : the list of negitive features to use in calculating the dtm products\n",
        "        ignore {list} : a list of features to ignore in the dtm product\n",
        "        Returns:\n",
        "        -------------\n",
        "        combined_scaled {pd.DataFrame} : A dataframe of the transformed document's tfidf\n",
        "        \"\"\"\n",
        "\n",
        "        dtm = [0] * 1000\n",
        "\n",
        "        for i in document.columns:\n",
        "            if i in ignore:\n",
        "                pass\n",
        "            else:\n",
        "                # takes the document term frequency and if it is\n",
        "                # a neg feature then we want to subtract  it from the combined dtm\n",
        "                if i in negative:\n",
        "                    dtm -= self.find_dtm(document[i])\n",
        "                # otherwise i want to add it to the combined dtm\n",
        "                else:\n",
        "                    dtm += self.find_dtm(document[i])\n",
        "\n",
        "        mm = MinMaxScaler()\n",
        "        combined_scaled_values = mm.fit_transform(dtm)\n",
        "        combined_scaled_columns = dtm.columns.tolist()\n",
        "        combined_scaled = pd.DataFrame(combined_scaled_values,\n",
        "                                       columns=combined_scaled_columns)\n",
        "        combined_scaled.fillna(0, inplace=True)\n",
        "        return combined_scaled, document.index.tolist()\n",
        "\n",
        "    def find_dtm(self, feature):\n",
        "        \"\"\"A function to take a feature and tokenize then return a tfidf df of that input\n",
        "        \"\"\"\n",
        "        self.tokenizer.fit_on_texts(feature)\n",
        "        a = self.tokenizer.texts_to_matrix(feature, mode='tfidf')\n",
        "        config = self.tokenizer.get_config()\n",
        "        feature_names = json_normalize(loads(\n",
        "            config['word_index'])).columns.tolist()\n",
        "        dtm = pd.DataFrame(a)\n",
        "        return dtm\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmYB3d9FpOzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr = Transformer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9vVHL60pOzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "negative = ['negative']\n",
        "ignore = []\n",
        "user_transformed, y = tr.transform(document=pd.DataFrame({'name': \"blue berry kush\",\n",
        "                  'race': 'sativa',\n",
        "                  'flavors': ['blueberry', 'sweet'],\n",
        "                  'negative': ['dry mouth', 'dry eyes'],\n",
        "                  'positive': ['creativity', 'stress'],\n",
        "                  'medical': ['ptsd', 'stress'],\n",
        "                  'description': \"blueberry kush my dude blueberry_kush:10, whitewhidow:10 \",\n",
        "                  }),negative=negative, ignore=ignore)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jyhoz3rpOzN",
        "colab_type": "code",
        "colab": {},
        "outputId": "23a05eac-419a-423f-eb08-45f27a51e566"
      },
      "source": [
        "user_transformed.iloc[0].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    996\n",
              "1.0      3\n",
              "1.0      1\n",
              "Name: 0, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPFe9v6wpOzQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "2f64900f-18a3-4fe8-f3ee-f6bba919382f"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsTransformer\n",
        "knn = KNeighborsTransformer()\n",
        "X_train,y_train = tr.transform(tr.df,negative,ignore)\n",
        "\n",
        "knn.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsTransformer()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9lEZYecpOzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./transformer.pickle','wb') as fp:\n",
        "    pickle.dump(tr, fp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uc-YB4RpOzV",
        "colab_type": "code",
        "colab": {},
        "outputId": "f2d4b2ab-0e99-4a72-d749-00ac3a5357c9"
      },
      "source": [
        "knn.kneighbors(X=user_transformed,n_neighbors=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[2.40560978, 2.55181968, 2.60670559, 2.63466242, 2.63672392],\n",
              "        [2.34029684, 2.44410932, 2.48769509, 2.49228827, 2.52441853]]),\n",
              " array([[ 138,  156,  803,  133,  170],\n",
              "        [ 136,  133,  130, 1458, 1452]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5SGXx87pOzX",
        "colab_type": "code",
        "colab": {},
        "outputId": "33fa331c-0190-48f4-a893-3b50f3944ce8"
      },
      "source": [
        "tr.df.iloc[170]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index                                       170\n",
              "id                                          234\n",
              "name                     Bhang Triple Berry Goo\n",
              "race                                     indica\n",
              "flavors         ['Berry', 'Apple', 'Blueberry']\n",
              "positive       ['Relaxed', 'Euphoric', 'Happy']\n",
              "negative              ['Dry Mouth', 'Dry Eyes']\n",
              "medical             ['Fatigue', 'Eye Pressure']\n",
              "description                              [None]\n",
              "Name: 170, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpv3Thv8pOzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./transformer.pickle','rb') as fp:\n",
        "    tr = pickle.load(fp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5q3xU-jpOza",
        "colab_type": "code",
        "colab": {},
        "outputId": "a0234655-4dfb-4b97-daf4-5e9561b3278a"
      },
      "source": [
        "type(tr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.Transformer"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RihGyM3RpOzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}